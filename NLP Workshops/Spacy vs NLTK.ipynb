{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Spacy</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "spaCy is an open-source natural language processing (NLP) library and framework designed for performing various NLP tasks in a seamless and efficient manner. It provides pre-trained models and linguistic data that enable users to perform tasks such as tokenization, part-of-speech tagging, named entity recognition, dependency parsing, and more. spaCy is written in Python and is known for its speed and accuracy, making it a popular choice for developers, researchers, and organizations working with text data. It simplifies the process of extracting linguistic information from text and is widely used in applications like text analysis, information extraction, chatbots, and language understanding tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>NLTK</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK, short for Natural Language Toolkit, is a comprehensive open-source library for natural language processing (NLP) in the Python programming language. It provides tools, resources, and libraries for working with human language data and performing various NLP tasks. NLTK offers functionalities for tasks such as tokenization, stemming, lemmatization, part-of-speech tagging, parsing, and semantic analysis, among others. It also includes corpora and lexical resources for research and experimentation in NLP. NLTK is widely used by developers, researchers, and educators in the fields of computational linguistics and NLP to build and explore NLP applications, conduct linguistic research, and teach NLP concepts. Its flexibility and extensibility make it a valuable tool for a wide range of text processing and language analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Spacy VS NLTK</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NLTK, short for Natural Language Toolkit, is a comprehensive open-source library for natural language processing (NLP) in the Python programming language. It provides tools, resources, and libraries for working with human language data and performing various NLP tasks. NLTK offers functionalities for tasks such as tokenization, stemming, lemmatization, part-of-speech tagging, parsing, and semantic analysis, among others. It also includes corpora and lexical resources for research and experimentation in NLP. NLTK is widely used by developers, researchers, and educators in the fields of computational linguistics and NLP to build and explore NLP applications, conduct linguistic research, and teach NLP concepts. Its flexibility and extensibility make it a valuable tool for a wide range of text processing and language analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Ease of Use:</h2>\n",
    "\n",
    "<h4> spaCy :</h4>is known for its simplicity and ease of use. Its API is designed to be user-friendly, and it offers pre-trained models that make it easy to get started with common NLP tasks.\n",
    "<h4>NLTK :</h4> NLTK, while powerful, can sometimes have a steeper learning curve due to its extensive feature set and the need to assemble various components for specific tasks.\n",
    "<h2>Performance:</h2>\n",
    "\n",
    "<h4>spaCy:</h4> spaCy is known for its speed and efficiency. It is optimized for production use and is significantly faster than NLTK for most tasks.\n",
    "<h4>NLTK:</h4> NLTK may be slower than spaCy for some operations due to its pure Python implementation, although this difference may not be significant for smaller datasets.\n",
    "<h2>Pre-trained Models:</h2>\n",
    "\n",
    "<h4>spaCy:</h4> spaCy provides pre-trained models for various languages, which are trained on large corpora and can be used for tasks like part-of-speech tagging, named entity recognition, and dependency parsing.\n",
    "<h4>NLTK :</h4> NLTK also offers pre-trained models and corpora, but they may require additional setup and customization for specific tasks.\n",
    "<h2>NLP Components:</h2>\n",
    "\n",
    "<h4>spaCy:</h4>spaCy includes a wide range of NLP components, such as named entity recognition, part-of-speech tagging, dependency parsing, and sentence segmentation, in a unified framework.\n",
    "<h4>NLTK :</h4>NLTK provides a more modular approach, allowing users to select and combine individual components for their specific NLP needs.\n",
    "<h2>Community and Documentation:</h2>\n",
    "\n",
    "Both spaCy and NLTK have active communities and extensive documentation. NLTK, being older, has a larger repository of tutorials and resources, while spaCy's documentation is well-organized and beginner-friendly.\n",
    "<h2>Use Cases:</h2>\n",
    "\n",
    "<h4>spaCy:</h4>spaCy is often a preferred choice for production-level NLP applications due to its speed and ease of use. It's suitable for a wide range of NLP tasks and is widely used in industry applications.\n",
    "<h4>NLTK :</h4>NLTK is well-suited for educational purposes, research, and experimentation in NLP. It's a valuable tool for learning about NLP algorithms and linguistics.\n",
    "In summary, the choice between spaCy and NLTK depends on your specific needs. If you want a fast and efficient library for production-level NLP tasks, spaCy is a solid choice. On the other hand, if you're looking for a more educational or research-oriented toolkit with a wide range of NLP components, NLTK might be a better fit. Some practitioners also choose to use both libraries in different parts of their NLP workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Installation instructions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install spacy\n",
    "\n",
    "python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sentence & Word Tokenization In Spacy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Strange loves pav bhaji of mumbai.\n",
      "Hulk loves chat of delhi\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "mumbai\n",
      ".\n",
      "Hulk\n",
      "loves\n",
      "chat\n",
      "of\n",
      "delhi\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    for word in sentence:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sentence & Word Tokenization In NLTK</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\super\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.', 'Strange loves pav bhaji of mumbai.', 'Hulk loves chat of delhi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr',\n",
       " '.',\n",
       " 'Strange',\n",
       " 'loves',\n",
       " 'pav',\n",
       " 'bhaji',\n",
       " 'of',\n",
       " 'mumbai',\n",
       " '.',\n",
       " 'Hulk',\n",
       " 'loves',\n",
       " 'chat',\n",
       " 'of',\n",
       " 'delhi']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From above code you can see that Spacy is object oriented whereas NLTK is a string processing library**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
